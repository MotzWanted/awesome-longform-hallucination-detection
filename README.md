<h2 align="center">Awesome longform Hallucination Detection & Migration </h2>

<p>
This repository contains hand-curated resources for Long-form hallucinations detection with a focus on Generative Pre-trained Transformer (GPT). 
  Long-form text generation is widely used in large language models (LLMs), as referenced in studies [2, 3]. However, with longer texts, these models are more likely to generate nonsenical content, coined as "hallucinations", making it more challenging to evaluate [1]. 

One major issue is that benchmarks for detecting hallucinations in LLMs are often limited to short, factual questions and answers. Additionally, evaluating these hallucinations in long-form content is complex. The current evaluation methods have their limitations, especially when dealing with complex, debatable facts or when different sources provide conflicting information. These challenges complicate the use of LLMs for applications that mimic real-world situations.

</p>
 <h4 align="center">
  
  <a href="https://awesome.re">
    <img src="https://awesome.re/badge.svg" alt="Awesome" />
  </a>
  <a href="https://github.com/MotzWanted/awesome-longform-hallucination-detection/blob/main/LICENSE">
    <img src="https://img.shields.io/badge/License-Apache_2.0-blue.svg" alt="MotzWanted/awesome-longform-hallucination-detection is released under the Apache 2.0 license." />
  </a>
  <a href="http://makeapullrequest.com">
    <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="http://makeapullrequest.com" />
  </a>
</h4>


# Table of Contents

- [Papers](#papers)
- [Other Resources](#blogs)

## Papers
üìÑ

|      Paper Title                | Year  | Code |
| :-------------------- | :----------: | :----------: |
| [FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation](https://arxiv.org/abs/2305.14251) | 2023 | [[Github]](https://github.com/shmsw25/FActScore) |
| [Investigating Answerability of LLMs for Long-Form Question Answering](https://arxiv.org/abs/2309.08210) | 2023 |  |
| [Understanding Retrieval Augmentation for Long-Form Question Answering](https://arxiv.org/abs/2310.12150) | 2023 |  |
| [Fast and Accurate Factual Inconsistency Detection Over Long Documents](https://arxiv.org/abs/2310.13189) | 2023 | [[Github]](https://github.com/asappresearch/scale-score)  |


## Other [ Blog etc ]
üë©‚Äçüè´

|      Paper Title                | Year  |
| :-------------------- | :----------: |
| [The Hallucinations Leaderboard](https://huggingface.co/blog/leaderboards-on-the-hub-hallucinations) | 2023 |
